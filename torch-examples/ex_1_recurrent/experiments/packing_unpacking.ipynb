{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os.path\n",
    "import pandas as pn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from itertools import count\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f42e09eeb90>"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.autograd as autograd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import DataLoader, TensorDataset, Dataset\n",
    "import torch.utils.data\n",
    "\n",
    "torch.set_default_dtype(torch.double)\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.utils.rnn as rnn_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensor_seq_to_onehot(s,nlabels):\n",
    "    bar = torch.zeros(s.shape[0],1,nlabels)\n",
    "    bar.scatter_(-1,s.view(-1,1,1),1)\n",
    "    return bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyAuto(torch.nn.Module):\n",
    "    def __init__(self,N_SYMBOLS):\n",
    "        super(MyAuto,self).__init__()\n",
    "        self.N_SYMBOLS = N_SYMBOLS\n",
    "        self.N_hidden = 30\n",
    "        self.D_embed = 20\n",
    "        self.embedding = nn.Embedding(N_SYMBOLS,self.D_embed,padding_idx=0)\n",
    "        self.encoder = nn.RNN(self.D_embed,self.N_hidden,2,dropout=0.1)\n",
    "        #self.encoder = nn.Identity()\n",
    "        self.d1 = nn.Linear(self.N_hidden,N_SYMBOLS)\n",
    "        self.d2 = nn.Softmax(dim=-1)\n",
    "    \n",
    "    def forward(self, some_data):\n",
    "        is_packed = isinstance(some_data,rnn_utils.PackedSequence)\n",
    "        \n",
    "        if is_packed:\n",
    "            embedded_data = self.embedding(some_data.data)\n",
    "        else:\n",
    "            embedded_data = self.embedding(some_data)\n",
    "        \n",
    "        if len(embedded_data.shape) > 3: #Embedding adds an extra dimension\n",
    "            embedded_data = torch.flatten(embedded_data,-2)\n",
    "        \n",
    "        assert len(embedded_data.shape) == 3 , \"Data embedded with shape {}\".format(embedded_data.shape)\n",
    "        \n",
    "        outputs,hidden = self.encoder(embedded_data)\n",
    "        #outputs = self.encoder(embedded_data)\n",
    "        x = self.d1(outputs)\n",
    "        y = self.d2(x)\n",
    "        if is_packed:\n",
    "            return rnn_utils.PackedSequence(y,some_data.batch_sizes,some_data.sorted_indices, some_data.unsorted_indices)\n",
    "        else:\n",
    "            return y\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyAuto(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_SYMBOLS = 20 #reserve the 1 and 0 symbol for start and stop\n",
    "M_SEQS = 31\n",
    "L_SEQS = (20,50)\n",
    "\n",
    "import random as pyrand\n",
    "#create sequences as 1-d long tensors\n",
    "basic_sequence_lengths = torch.LongTensor(M_SEQS).random_(*L_SEQS)\n",
    "basic_sequences = [torch.LongTensor(i.item()).random_(2,N_SYMBOLS) for i in basic_sequence_lengths]\n",
    "for i in basic_sequences:\n",
    "    i[0] = 1\n",
    "    i[-1] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For individual sequences, it should only be two dimensions with the first dimension as time.\n",
    "torch_shaped_sequences = [i.reshape(-1,1) for i in basic_sequences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([29, 1, 20])"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#embedding adds an additional dimension, rather than just expand into an existing dimension.\n",
    "model.embedding(torch_shaped_sequences[0].reshape(-1,1)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Experiments about padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "padded shape, basic:  torch.Size([49, 31])\n",
      "shape after embedding:  torch.Size([49, 31, 20])\n",
      "Can run model on this? torch.Size([49, 31, 20])\n"
     ]
    }
   ],
   "source": [
    "padded_torch_seqs = rnn_utils.pad_sequence(basic_sequences)\n",
    "print(\"padded shape, basic: \" , padded_torch_seqs.shape)\n",
    "print(\"shape after embedding: \", model.embedding(padded_torch_seqs).shape)\n",
    "print(\"Can run model on this?\", model(padded_torch_seqs).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "padded shape, torch_shaped:  torch.Size([49, 31, 1])\n",
      "shape after embedding:  torch.Size([49, 31, 1, 20])\n",
      "\t(Note the added extra dimension, handled in the model)\n",
      "Can run model on this? torch.Size([49, 31, 20])\n"
     ]
    }
   ],
   "source": [
    "padded_torch_seqs = rnn_utils.pad_sequence(torch_shaped_sequences)\n",
    "print(\"padded shape, torch_shaped: \", padded_torch_seqs.shape)\n",
    "print(\"shape after embedding: \", model.embedding(padded_torch_seqs).shape)\n",
    "print(\"\\t(Note the added extra dimension, handled in the model)\")\n",
    "print(\"Can run model on this?\", model(padded_torch_seqs).shape) #Because the model automagically handles that extra coordinate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "#experiments about packing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "packed shape : torch.Size([1083])\n",
      "shape after embedding : torch.Size([1083, 20])\n",
      "\n",
      "\tCan't run model.\n"
     ]
    }
   ],
   "source": [
    "packed_torch_seqs = rnn_utils.pack_sequence(basic_sequences,enforce_sorted=False)\n",
    "print(\"packed shape :\", packed_torch_seqs.data.shape)\n",
    "print(\"shape after embedding :\", model.embedding(packed_torch_seqs.data).shape)\n",
    "try:\n",
    "    print(\"Can run model on this?\",model(packed_torch_seqs).data.shape)\n",
    "except:\n",
    "    print(\"\\n\\tCan't run model.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "packed shape : torch.Size([1083, 1])\n",
      "shape after embedding : torch.Size([1083, 1, 20])\n",
      "Can run model on this? torch.Size([1083, 1, 20])\n"
     ]
    }
   ],
   "source": [
    "packed_torch_seqs = rnn_utils.pack_sequence(torch_shaped_sequences,enforce_sorted=False)\n",
    "print(\"packed shape :\", packed_torch_seqs.data.shape)\n",
    "print(\"shape after embedding :\", model.embedding(packed_torch_seqs.data).shape)\n",
    "print(\"Can run model on this?\",model(packed_torch_seqs).data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "packed shape : torch.Size([1083, 1])\n",
      "shape after embedding : torch.Size([49, 31, 1, 20])\n",
      "Can run model on this? torch.Size([1083, 1, 20])\n"
     ]
    }
   ],
   "source": [
    "packed_torch_seqs = rnn_utils.pack_sequence(torch_shaped_sequences,enforce_sorted=False)\n",
    "print(\"packed shape :\", packed_torch_seqs.data.shape)\n",
    "unpacked_torch_seqs, unpacked_lengths = rnn_utils.pad_packed_sequence(packed_torch_seqs)\n",
    "\n",
    "print(\"shape after embedding :\", model.embedding(unpacked_torch_seqs).shape)\n",
    "print(\"Can run model on this?\",model(packed_torch_seqs).data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([49, 31, 1])"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unpacked_torch_seqs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "blah = model.embedding(unpacked_torch_seqs)\n",
    "repacked = rnn_utils.pack_padded_sequence(torch.flatten(blah,-2),unpacked_lengths,enforce_sorted=False)\n",
    "output, hidden = model.encoder(repacked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 31, 30])"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1083, 30])"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
