{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "alldev = !ls /sigmorphon2020/task0-data/*/*.dev\n",
    "alltrn = !ls /sigmorphon2020/task0-data/*/*.trn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "alldata = alldev+alltrn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shared.unimorph_loader.provided as unl\n",
    "import os.path\n",
    "import pandas as pn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "everything = [(os.path.basename(i),unl.read_unimorph_tsv(i)) for i in alldata[:2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_lemmata = list()\n",
    "for langname, lang in everything:\n",
    "    for lem in lang[\"lemma\"]:\n",
    "        all_lemmata.append(lem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "187"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_lemmata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shared.unimorph_loader.alphabets as alpha\n",
    "from itertools import count\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_alpha = alpha.get_master_alphabet()\n",
    "my_alpha_lookup = OrderedDict(zip(my_alpha,count()))\n",
    "START_TOK = my_alpha[1]\n",
    "END_TOK = my_alpha[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_converted_lemmata = [ [1] + [my_alpha_lookup[j] for j in lem.lower()] + [0] for lem in all_lemmata]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lem_seq_to_onehot(one_seq,alph_len):\n",
    "    one_hot_version = torch.zeros(one_seq.shape[0],1,alph_len)\n",
    "    one_hot_version[:,0,one_seq[:,0]] = 1.0\n",
    "    return one_hot_version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f8bfdc74b50>"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.autograd as autograd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import DataLoader, TensorDataset, Dataset\n",
    "import torch.utils.data\n",
    "\n",
    "torch.set_default_dtype(torch.double)\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.utils.rnn as rnn_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyAuto(torch.nn.Module):\n",
    "    def __init__(self,an_alphabet):\n",
    "        super(MyAuto,self).__init__()\n",
    "        self.N_hidden = 300\n",
    "        self.D_embed = 200\n",
    "        self.embedding = nn.Embedding(len(an_alphabet),self.D_embed)\n",
    "        self.encoder = nn.RNN(self.D_embed,self.N_hidden,2,dropout=0.1)\n",
    "        #self.encoder = nn.Identity()\n",
    "        self.d1 = nn.Linear(self.N_hidden,len(an_alphabet))\n",
    "        self.d2 = nn.Softmax(dim=-1)\n",
    "    \n",
    "    def forward(self, some_data):\n",
    "        is_packed = isinstance(some_data,rnn_utils.PackedSequence)\n",
    "        \n",
    "        if is_packed:\n",
    "            embedded_data = self.embedding(some_data.data)\n",
    "        else:\n",
    "            embedded_data = self.embedding(some_data)\n",
    "        outputs,hidden = self.encoder(embedded_data)\n",
    "        #outputs = self.encoder(embedded_data)\n",
    "        x = self.d1(outputs)\n",
    "        y = self.d2(x)\n",
    "        if is_packed:\n",
    "            return rnn_utils.PackedSequence(y,some_data.batch_sizes,some_data.sorted_indices, some_data.unsorted_indices)\n",
    "        else:\n",
    "            return y\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyAuto(torch.nn.Module):\n",
    "    def __init__(self,an_alphabet):\n",
    "        super(MyAuto,self).__init__()\n",
    "        self.N_hidden = 300\n",
    "        self.D_embed = 20\n",
    "        self.embedding = nn.Embedding(len(an_alphabet),self.D_embed)\n",
    "        self.d1 = nn.Linear(self.D_embed,len(an_alphabet))\n",
    "        self.d2 = nn.Softmax(dim=-1)\n",
    "    \n",
    "    def forward(self, some_data):\n",
    "        is_packed = isinstance(some_data,rnn_utils.PackedSequence)\n",
    "        \n",
    "        if is_packed:\n",
    "            embedded_data = self.embedding(some_data.data)\n",
    "        else:\n",
    "            embedded_data = self.embedding(some_data)\n",
    "        #outputs,hidden = self.encoder(embedded_data)\n",
    "        \n",
    "        x = self.d1(embedded_data)\n",
    "        y = self.d2(x)\n",
    "        if is_packed:\n",
    "            return rnn_utils.PackedSequence(y,some_data.batch_sizes,some_data.sorted_indices, some_data.unsorted_indices)\n",
    "        else:\n",
    "            return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensor_seq_to_onehot(s,nlabels=len(my_alpha)):\n",
    "    bar = torch.zeros(s.shape[0],1,nlabels)\n",
    "    bar.scatter_(-1,s.view(-1,1,1),1)\n",
    "    return bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_t_lemmata = [torch.LongTensor(i).reshape(-1,1) for i in all_converted_lemmata]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_oh_lemmata = [tensor_seq_to_onehot(i) for i in all_t_lemmata]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "187"
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_t_lemmata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyAuto(my_alpha)\n",
    "model.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "myloss = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "opt = torch.optim.SGD(model.parameters(),lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "tensor([0.8312])\n",
      "200\n",
      "tensor([0.8309])\n",
      "400\n",
      "tensor([0.8307])\n",
      "600\n",
      "tensor([0.8304])\n",
      "800\n",
      "tensor([0.8300])\n",
      "1000\n",
      "tensor([0.8296])\n",
      "1200\n",
      "tensor([0.8292])\n",
      "1400\n",
      "tensor([0.8287])\n",
      "1600\n",
      "tensor([0.8281])\n",
      "1800\n",
      "tensor([0.8273])\n",
      "2000\n",
      "tensor([0.8264])\n",
      "2200\n",
      "tensor([0.8252])\n",
      "2400\n",
      "tensor([0.8235])\n",
      "2600\n",
      "tensor([0.8209])\n",
      "2800\n",
      "tensor([0.8166])\n",
      "3000\n",
      "tensor([0.8087])\n",
      "3200\n",
      "tensor([0.7939])\n",
      "3400\n",
      "tensor([0.7765])\n",
      "3600\n",
      "tensor([0.7668])\n",
      "3800\n",
      "tensor([0.7626])\n",
      "4000\n",
      "tensor([0.7605])\n",
      "4200\n",
      "tensor([0.7591])\n",
      "4400\n",
      "tensor([0.7580])\n",
      "4600\n",
      "tensor([0.7571])\n",
      "4800\n",
      "tensor([0.7562])\n",
      "5000\n",
      "tensor([0.7554])\n",
      "5200\n",
      "tensor([0.7544])\n",
      "5400\n",
      "tensor([0.7534])\n",
      "5600\n",
      "tensor([0.7522])\n",
      "5800\n",
      "tensor([0.7508])\n",
      "6000\n",
      "tensor([0.7492])\n",
      "6200\n",
      "tensor([0.7471])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-342-0140a9a7f184>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mpacked_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrnn_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_t_lemmata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0menforce_sorted\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mpacked_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrnn_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_oh_lemmata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0menforce_sorted\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpacked_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/utils/rnn.py\u001b[0m in \u001b[0;36mpack_sequence\u001b[0;34m(sequences, enforce_sorted)\u001b[0m\n\u001b[1;32m    377\u001b[0m     \"\"\"\n\u001b[1;32m    378\u001b[0m     \u001b[0mlengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msequences\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 379\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mpack_padded_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpad_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menforce_sorted\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0menforce_sorted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/utils/rnn.py\u001b[0m in \u001b[0;36mpad_sequence\u001b[0;34m(sequences, batch_first, padding_value)\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0mout_dims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmax_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtrailing_dims\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 335\u001b[0;31m     \u001b[0mout_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msequences\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mout_dims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfill_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpadding_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    336\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m         \u001b[0mlength\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(10000):\n",
    "    model.zero_grad()\n",
    "    \n",
    "    for j in range(10,len(all_t_lemmata),10):\n",
    "        \n",
    "        packed_x = rnn_utils.pack_sequence(all_t_lemmata[j-10:j],enforce_sorted=False)\n",
    "        packed_y = rnn_utils.pack_sequence(all_oh_lemmata[j-10:j],enforce_sorted=False)\n",
    "        \n",
    "        pred = model(packed_x)\n",
    "        l = myloss(pred.data,packed_y.data)\n",
    "        l.backward()\n",
    "        \n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "    \n",
    "    if (i%200==0):\n",
    "        print(i)\n",
    "        with torch.no_grad():\n",
    "            total_loss = torch.tensor([0.0])\n",
    "            \n",
    "            for j in range(len(all_t_lemmata)):\n",
    "                pred = model(all_t_lemmata[j])\n",
    "                l = myloss(pred,all_oh_lemmata[j])\n",
    "                total_loss += l\n",
    "            print(total_loss)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[177],\n",
       "        [177],\n",
       "        [101],\n",
       "        [140],\n",
       "        [ 42],\n",
       "        [163],\n",
       "        [ 91],\n",
       "        [  7],\n",
       "        [  7],\n",
       "        [217]])"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(all_t_lemmata[0]).argmax(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = rnn_utils.pad_sequence(all_t_lemmata[:10])\n",
    "b = rnn_utils.pack_sequence(all_t_lemmata[:10],enforce_sorted=False)\n",
    "by = rnn_utils.pack_sequence(all_oh_lemmata[:10],enforce_sorted=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0044, grad_fn=<MseLossBackward>)"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myloss(model(b).data,by.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([104, 1, 200])"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.embedding(b.data).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10, 10, 10, 10, 10, 10, 10, 10,  9,  8,  5,  2])"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.batch_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PackedSequence(data=tensor([[ 1],\n",
       "        [ 1],\n",
       "        [ 1],\n",
       "        [ 1],\n",
       "        [ 1],\n",
       "        [ 1],\n",
       "        [ 1],\n",
       "        [ 1],\n",
       "        [ 1],\n",
       "        [ 1],\n",
       "        [44],\n",
       "        [44],\n",
       "        [44],\n",
       "        [44],\n",
       "        [44],\n",
       "        [44],\n",
       "        [44],\n",
       "        [44],\n",
       "        [44],\n",
       "        [44],\n",
       "        [46],\n",
       "        [46],\n",
       "        [46],\n",
       "        [46],\n",
       "        [46],\n",
       "        [46],\n",
       "        [46],\n",
       "        [46],\n",
       "        [46],\n",
       "        [46],\n",
       "        [47],\n",
       "        [39],\n",
       "        [47],\n",
       "        [33],\n",
       "        [47],\n",
       "        [47],\n",
       "        [47],\n",
       "        [44],\n",
       "        [38],\n",
       "        [42],\n",
       "        [32],\n",
       "        [40],\n",
       "        [32],\n",
       "        [32],\n",
       "        [32],\n",
       "        [32],\n",
       "        [32],\n",
       "        [32],\n",
       "        [52],\n",
       "        [52],\n",
       "        [51],\n",
       "        [45],\n",
       "        [33],\n",
       "        [43],\n",
       "        [38],\n",
       "        [51],\n",
       "        [51],\n",
       "        [45],\n",
       "        [45],\n",
       "        [39],\n",
       "        [40],\n",
       "        [52],\n",
       "        [40],\n",
       "        [40],\n",
       "        [32],\n",
       "        [32],\n",
       "        [32],\n",
       "        [36],\n",
       "        [40],\n",
       "        [32],\n",
       "        [45],\n",
       "        [44],\n",
       "        [43],\n",
       "        [38],\n",
       "        [44],\n",
       "        [32],\n",
       "        [32],\n",
       "        [39],\n",
       "        [51],\n",
       "        [ 0],\n",
       "        [11],\n",
       "        [35],\n",
       "        [40],\n",
       "        [56],\n",
       "        [32],\n",
       "        [50],\n",
       "        [50],\n",
       "        [46],\n",
       "        [ 0],\n",
       "        [32],\n",
       "        [46],\n",
       "        [45],\n",
       "        [32],\n",
       "        [56],\n",
       "        [ 0],\n",
       "        [ 0],\n",
       "        [ 0],\n",
       "        [54],\n",
       "        [44],\n",
       "        [ 0],\n",
       "        [ 0],\n",
       "        [ 0],\n",
       "        [ 0],\n",
       "        [ 0]]), batch_sizes=tensor([10, 10, 10, 10, 10, 10, 10, 10,  9,  8,  5,  2]), sorted_indices=tensor([1, 6, 2, 7, 8, 0, 5, 9, 4, 3]), unsorted_indices=tensor([5, 0, 2, 9, 8, 6, 1, 3, 4, 7]))"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.nn.utils.rnn.PackedSequence"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn_utils.PackedSequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 6, 2, 7, 8, 0, 5, 9, 4, 3])"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.sorted_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5, 0, 2, 9, 8, 6, 1, 3, 4, 7])"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.unsorted_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
