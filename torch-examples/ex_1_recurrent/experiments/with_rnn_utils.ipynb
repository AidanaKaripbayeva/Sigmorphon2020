{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os.path\n",
    "import pandas as pn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from itertools import count\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7ff294df1410>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.autograd as autograd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import DataLoader, TensorDataset, Dataset\n",
    "import torch.utils.data\n",
    "\n",
    "torch.set_default_dtype(torch.double)\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.utils.rnn as rnn_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensor_seq_to_onehot(s,nlabels):\n",
    "    bar = torch.zeros(s.shape[0],1,nlabels)\n",
    "    bar.scatter_(-1,s.view(-1,1,1),1)\n",
    "    return bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"code\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.rnns import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyAuto(torch.nn.Module):\n",
    "    def __init__(self,N_SYMBOLS):\n",
    "        super(MyAuto,self).__init__()\n",
    "        self.N_SYMBOLS = N_SYMBOLS\n",
    "        self.N_hidden = 30\n",
    "        self.D_embed = 21\n",
    "        \n",
    "        self.everything = RNN_Layers(\n",
    "            RNN_Input_Embedding( nn.Embedding(N_SYMBOLS,self.D_embed,padding_idx=0) )\n",
    "            , nn.RNN(self.D_embed,self.N_hidden,2,dropout=0.1)\n",
    "            , RNN_FFLayer(nn.Linear(self.N_hidden,N_SYMBOLS))\n",
    "            , RNN_FFLayer(nn.Softmax(dim=-1))\n",
    "        )\n",
    "    \n",
    "    def forward(self, some_data):\n",
    "        return self.everything(some_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyAuto(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_SYMBOLS = 20 #reserve the 1 and 0 symbol for start and stop\n",
    "M_SEQS = 31\n",
    "L_SEQS = (20,50)\n",
    "\n",
    "import random as pyrand\n",
    "#create sequences as 1-d long tensors\n",
    "basic_sequence_lengths = torch.LongTensor(M_SEQS).random_(*L_SEQS)\n",
    "basic_sequences = [torch.LongTensor(i.item()).random_(2,N_SYMBOLS) for i in basic_sequence_lengths]\n",
    "for i in basic_sequences:\n",
    "    i[0] = 1\n",
    "    i[-1] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For individual sequences, it should only be two dimensions with the first dimension as time.\n",
    "torch_shaped_sequences = [i.reshape(-1,1) for i in basic_sequences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Experiments about padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "padded shape, basic:  torch.Size([49, 31])\n",
      "shape after embedding:  torch.Size([49, 31, 21])\n",
      "Can run model on this? torch.Size([49, 31, 20])\n"
     ]
    }
   ],
   "source": [
    "padded_torch_seqs = rnn_utils.pad_sequence(basic_sequences)\n",
    "print(\"padded shape, basic: \" , padded_torch_seqs.shape)\n",
    "print(\"shape after embedding: \", model.everything.layers[0](padded_torch_seqs)[0].shape)\n",
    "print(\"Can run model on this?\", model(padded_torch_seqs)[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "padded shape, torch_shaped:  torch.Size([49, 31, 1])\n",
      "shape after embedding:  torch.Size([49, 31, 21])\n",
      "\t(Note the added extra dimension, handled in the model)\n",
      "Can run model on this? torch.Size([49, 31, 20])\n"
     ]
    }
   ],
   "source": [
    "padded_torch_seqs = rnn_utils.pad_sequence(torch_shaped_sequences)\n",
    "print(\"padded shape, torch_shaped: \", padded_torch_seqs.shape)\n",
    "print(\"shape after embedding: \", model.everything.layers[0](padded_torch_seqs)[0].shape)\n",
    "print(\"\\t(Note the added extra dimension, handled in the model)\")\n",
    "print(\"Can run model on this?\", model(padded_torch_seqs)[0].shape) #Because the model automagically handles that extra coordinate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#experiments about packing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "packed shape : torch.Size([1149])\n",
      "shape after embedding : torch.Size([49, 31, 21])\n",
      "Can run model on this? torch.Size([1149, 20])\n"
     ]
    }
   ],
   "source": [
    "packed_torch_seqs = rnn_utils.pack_sequence(basic_sequences,enforce_sorted=False)\n",
    "print(\"packed shape :\", packed_torch_seqs.data.shape)\n",
    "print(\"shape after embedding :\", model.everything.layers[0](padded_torch_seqs)[0].shape)\n",
    "#try:\n",
    "print(\"Can run model on this?\",model(packed_torch_seqs)[0].data.shape)\n",
    "#except Exception as e:\n",
    "#    print(\"\\n\\tCan't run model. {}\".format(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "packed shape : torch.Size([1149, 1])\n",
      "shape after embedding : torch.Size([49, 31, 21])\n",
      "Can run model on this? torch.Size([1149, 20])\n"
     ]
    }
   ],
   "source": [
    "packed_torch_seqs = rnn_utils.pack_sequence(torch_shaped_sequences,enforce_sorted=False)\n",
    "print(\"packed shape :\", packed_torch_seqs.data.shape)\n",
    "print(\"shape after embedding :\", model.everything.layers[0](padded_torch_seqs)[0].shape)\n",
    "print(\"Can run model on this?\",model(packed_torch_seqs)[0].data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Other experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "packed shape : torch.Size([1149, 1])\n",
      "shape after embedding : torch.Size([49, 31, 21])\n",
      "Can run model on this? torch.Size([1149, 20])\n"
     ]
    }
   ],
   "source": [
    "packed_torch_seqs = rnn_utils.pack_sequence(torch_shaped_sequences,enforce_sorted=False)\n",
    "print(\"packed shape :\", packed_torch_seqs.data.shape)\n",
    "unpacked_torch_seqs, unpacked_lengths = rnn_utils.pad_packed_sequence(packed_torch_seqs)\n",
    "\n",
    "print(\"shape after embedding :\", model.everything.layers[0](padded_torch_seqs)[0].shape)\n",
    "print(\"Can run model on this?\",model(packed_torch_seqs)[0].data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
