{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import re, collections\n",
    "from collections import Counter, defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_input(path):\n",
    "    lemma = []\n",
    "    tag = []\n",
    "    with open(path, encoding=\"utf8\") as file:\n",
    "        reader = csv.reader(file)\n",
    "        for row in reader:\n",
    "            #splitting the data by tabs\n",
    "            r = re.split(r'\\t+', row[0])\n",
    "            #appending lemma\n",
    "            lemma.append(r[0])\n",
    "            #splitting tags\n",
    "            t = r[2].split(';')\n",
    "            #appending only the first tag\n",
    "            tag.append(t[0])\n",
    "    return lemma, tag\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "INVAR_POS = {'V': {'V', 'V.PTCP', 'V.CVB'}, 'N': {'N'}, 'ADJ': {'ADJ'}}\n",
    "MORBOUND = '^'\n",
    "\n",
    "def parts_of_speech(lemma, tag):\n",
    "    \n",
    "    assert len (lemma) == len (tag)\n",
    "    pos_lemma = {} # pos: {lemmas}\n",
    "    unique_words = set([])\n",
    "    \n",
    "    #splitting lemmas into parts of speech\n",
    "    for i in range(len(tag)):\n",
    "        cat = [x for x in INVAR_POS for y in INVAR_POS[x] if y == tag[i]][0]\n",
    "        pos_lemma[cat] = pos_lemma.get(cat, set([]))\n",
    "        pos_lemma[cat].add (lemma[i])\n",
    "        unique_words.add((lemma[i], cat))\n",
    "    \n",
    "    # print the result\n",
    "    print(\"POSes in dataset:\", set(tag))\n",
    "    print (\"Num unique (word,pos):\", len(unique_words), \"/\", len(lemma))\n",
    "    for x in pos_lemma:\n",
    "        print (x + '\\t\\t', end='')\n",
    "    print ('\\n', end = '')\n",
    "    for x in pos_lemma:\n",
    "        print (len (pos_lemma[x]), '\\t\\t', end = '')\n",
    "    print ('\\n', end = '')\n",
    "    for i in range(10):\n",
    "        for x in pos_lemma:\n",
    "            print (list(pos_lemma[x])[i] + '\\t',end = '')\n",
    "        print ('\\n', end = '')\n",
    "    \n",
    "    return pos_lemma\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POSes in dataset: {'V', 'V.PTCP'}\n",
      "Num unique (word,pos): 3723 / 10000\n",
      "V\t\t\n",
      "3723 \t\t\n",
      "aligeirar\t\n",
      "ondear\t\n",
      "descercar\t\n",
      "automatizar\t\n",
      "relaxar\t\n",
      "aquartelar\t\n",
      "desanimar\t\n",
      "lotear\t\n",
      "arrazoar\t\n",
      "antecipar\t\n"
     ]
    }
   ],
   "source": [
    "#path = \"../../bpe_data/russian-train-high.txt\"\n",
    "path = \"../../bpe_data/portuguese-train-high.txt\"\n",
    "lemmas, poses = read_input(path)\n",
    "\n",
    "pos_lemma = parts_of_speech(lemmas, poses)\n",
    "#print (len(adj), len(v), len(n), list_of_numbers[:10])\n",
    "#pos_lemma\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ntar', 107, 0.22061855670103092, 0.028740263228579102, 0.0),\n",
       " ('tar', 485, 0.15645161290322582, 0.13027128659683052, 0.22061855670103092),\n",
       " ('rar', 324, 0.12390057361376673, 0.08702659145850121, 0.0),\n",
       " ('ar', 3100, 0.83266183185603, 0.83266183185603, 0.2609677419354839),\n",
       " ('cer', 111, 0.3447204968944099, 0.029814665592264304, 0.0),\n",
       " ('er', 322, 0.5168539325842697, 0.08648939027665861, 0.3447204968944099),\n",
       " ('ir', 280, 0.449438202247191, 0.07520816545796401, 0.0)]"
      ]
     },
     "execution_count": 366,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def test(word, suffs):\n",
    "    for suff in suffs:\n",
    "        if word[len(word)-len(suff):] == suff:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def bpe(list_of_lemmas, percentage, abs_min, subcoverage, total_n):\n",
    "    counts = {}\n",
    "    for word in list_of_lemmas:\n",
    "        if (len(word)) < 2:\n",
    "            continue\n",
    "        comb = word[-2] + word[-1]\n",
    "        counts[comb] = counts.get(comb, 0) + 1\n",
    "    \n",
    "    counts = [(x[0], x[1], x[1] / len(list_of_lemmas), x[1]/total_n) for x in counts.items()]\n",
    "    counts = sorted(counts, key = lambda x: -x[1])\n",
    "    bests = list(filter(lambda x: x[1] > abs_min and x[2] > percentage, counts))\n",
    "    #print (counts)\n",
    "    #print (bests,  sum([x[1] for x in counts if x[2] <= percentage]), sum([x[2] for x in counts if x[2] <= percentage]))\n",
    "    #print ('------')\n",
    "    \n",
    "    \n",
    "    if len(bests) == 0:\n",
    "        return []\n",
    "    #ret = [b for b in bests]\n",
    "    ret = []\n",
    "    for x in bests:\n",
    "        new_input = [word[:-2] + [x[0]] for word in list_of_lemmas if word[-2] + word[-1] == x[0]]\n",
    "        daughters = bpe(new_input, percentage, abs_min, subcoverage,total_n)\n",
    "        \n",
    "        perc_covered_by_daughters = len([word for word in new_input if test(''.join(word), [d[0] for d in daughters])]) / len(new_input)\n",
    "        #print ('daughters', perc_covered_by_daughters, daughters, x)\n",
    "        \n",
    "        # NOTE: if testing for good subpartition (else reject daughters), do:\n",
    "#         if perc_covered_by_daughters <= subcoverage:\n",
    "#             ret += [tuple(list(x) + [perc_covered_by_daughters])]\n",
    "#         else:\n",
    "#             ret += daughters\n",
    "        # OTHERWISE:\n",
    "        ret += daughters\n",
    "        if perc_covered_by_daughters <= subcoverage:\n",
    "           ret += [tuple(list(x) + [perc_covered_by_daughters])]\n",
    "        \n",
    "    if  sum([x[2] for x in counts if x[2] <= percentage]) > percentage:\n",
    "        ret += bpe([word for word in list_of_lemmas if word[-2] + word[-1] not in set([b[0] for b in bests])], percentage, abs_min, subcoverage,total_n)\n",
    "    \n",
    "    return ret\n",
    "\n",
    "\n",
    "class BpeModel(object):\n",
    "    \n",
    "    def __init__(self, pos, percentage = 0.1, abs_min = 100, subcoverage = 0.8):\n",
    "        self.pos = pos\n",
    "        self.suffixes = {'ab'}\n",
    "        self.percentage = percentage\n",
    "        self.abs_min = 100\n",
    "        self.subcoverage = subcoverage\n",
    "        \n",
    "    \n",
    "    def fit(self, set_of_lemmas):\n",
    "        vocab = [list(lem) + [''] for lem in set_of_lemmas]\n",
    "        self.suffixes = bpe(vocab, self.percentage, self.abs_min, self.subcoverage,len(set_of_lemmas))\n",
    "    \n",
    "    def transform(self,word):\n",
    "        res = word + MORBOUND\n",
    "        for suff in self.suffixes:\n",
    "            if word[len(word)-len(suff):] == suff:\n",
    "                res = word[:len(word)-len(suff)] + MORBOUND + suff\n",
    "        return res\n",
    "\n",
    "    \n",
    "\n",
    "bpe_model = BpeModel('V',percentage=.12,subcoverage=0.75)\n",
    "bpe_model.fit(pos_lemma['V'])\n",
    "bpe_model.suffixes\n",
    "\n",
    "#bpe_model = BpeModel('ADJ')\n",
    "#bpe_model.fit(pos_lemma['ADJ'])\n",
    "#bpe_model.suffixes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'a' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-120-3f786850e387>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'a' is not defined"
     ]
    }
   ],
   "source": [
    "# ADJ:\n",
    "#     ый\n",
    "#     ий\n",
    "#     ой\n",
    "# N:\n",
    "#     а\n",
    "#     о\n",
    "#     ø\n",
    "#     ь\n",
    "#     е\n",
    "#     я\n",
    "#     ия\n",
    "#     ие\n",
    "# V:\n",
    "#     ать\n",
    "#     ить\n",
    "#     ять    ся\n",
    "#     еть\n",
    "#     уть\n",
    "#     ти   сь"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
